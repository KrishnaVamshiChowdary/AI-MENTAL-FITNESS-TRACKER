import warnings
warnings.filterwarnings('ignore')
import numpy as np
import pandas as pd
from google.colab import drive
drive.mount('/content/drive')
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
df2.head()
merged_data = pd.merge(df1,df2)
merged_data
merged_data.isnull().sum()
merged_data.drop(columns = 'Code' , inplace = True)
merged_data.head
merged_data.shape
plt.figure(figsize = (12,6), layout = "constrained")
sns.heatmap(merged_data.corr(), annot=True, cmap="crest")
plt.show()
plt.figure(layout = "compressed")
sns.pairplot(merged_data, corner = True)
plt.show()
mean = merged_data["Mental"].mean()
mean
fig = px.pie(merged_data, values = "Mental", names = "Year")
fig.show()
fig = px.line(merged_data, x = "Year", y = "Mental", color = "Country", markers = True, color_discrete_sequence = ['red','lemonchiffon'], template = "plotly_dark")
fig.show()
# copying merged data to another variable to perform operation
df = merged_data
df.info() # diaplaying the data information
# reformatting the data checking up for invalid datatypes to avoid errors while evaluation
from sklearn.preprocessing import LabelEncoder
l = LabelEncoder()
for i in df.columns:
  if df[i].dtype == 'object':
    df[i]=l.fit_transform(df[i])
df.info(), 
df.shape
# spliting the data into train:test::.80:.20
x = df.drop("Mental", axis = 1) # x contains the data without the Mental column
y = df["Mental"]  # y contains just the Mental column

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = .20, random_state=2) # both x and y is divided into .80 and .20 parts for train and test
# printing the splitted data [train dataset and test dataset]
print(f'xtrain data size: {xtrain.shape}, xtest data size: {xtest.shape}')
print(f"ytrain data size: {ytrain.shape}, ytest data size: {ytest.shape}")
# Performing Linear Regression Model on the train dataset
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error,r2_score
lr = LinearRegression()
lr.fit(xtrain, ytrain)

ytrain_pred_lr = lr.predict(xtrain)
mse_lr = mean_squared_error(ytrain, ytrain_pred_lr)
rmse_lr = (np.sqrt(mse_lr))
r2_lr = r2_score(ytrain, ytrain_pred_lr)

print("Performing Linear Regression Model")
print("----------------------------------")
print(f"Mean Square Error: {mse_lr}")
print(f"Root Mean Square Error: {rmse_lr}")
print(f"R2 Score of the model: {r2_lr}")
# Performing Random Forest Resgression Model on the train dataset
from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()
rf.fit(xtrain, ytrain)

ytrain_pred_rf = rf.predict(xtrain)
mse_rf = mean_squared_error(ytrain, ytrain_pred_rf)
rmse_rf = (np.sqrt(mse_rf))
r2_rf = r2_score(ytrain, ytrain_pred_rf)

print("Performing Random Forest Regression Model")
print("-----------------------------------------")
print(f"Mean Square Error: {mse_rf}")
print(f"Root Mean Square Error: {rmse_rf}")
print(f"R2 Score of the model: {r2_rf}")
# Performing Linear Regression Model on the test dataset

ytest_pred_lr = lr.predict(xtest)
mse_lr = mean_squared_error(ytest, ytest_pred_lr)
rmse_lr = (np.sqrt(mse_lr))
r2_lr = r2_score(ytest, ytest_pred_lr)

print("Performing Linear Regression Model")
print("----------------------------------")
print(f"Mean Square Error: {mse_lr}")
print(f"Root Mean Square Error: {rmse_lr}")
print(f"R2 Score of the model: {r2_lr}")
print('\n\n')

# Random Forest Regression Model on the test dataset

ytest_pred_rf = rf.predict(xtest)
mse_rf = mean_squared_error(ytest, ytest_pred_rf)
rmse_rf = (np.sqrt(mse_rf))
r2_rf = r2_score(ytest, ytest_pred_rf)

print("Performing Random Forest Regression Model")
print("-----------------------------------------")
print(f"Mean Square Error: {mse_rf}")
print(f"Root Mean Square Error: {rmse_rf}")
print(f"R2 Score of the model: {r2_rf}")
